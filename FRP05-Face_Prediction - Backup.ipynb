{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "detector = MTCNN()\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,ZeroPadding2D\n",
    "from tensorflow.keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow.keras.backend as k\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\MySQL\\\\image\\\\celeb_faces_images_train'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:\\\\MySQL\\\\image\\\\celeb_faces_images_train\")\n",
    "base_dir = os.getcwd()\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(128,128, 3)))\n",
    "#model.add(Convolution2D(64, (3,3), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "#model.add(Dense(units=5,kernel_initializer='glorot_uniform',activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 130, 130, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 66, 66, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 128)       36992     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 524288)            0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 524288)            0         \n",
      "=================================================================\n",
      "Total params: 37,888\n",
      "Trainable params: 37,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = load_model('5_cel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ben_afflek', 'elton_john', 'jerry_seinfeld', 'madonna',\n",
       "       'mindy_kaling'], dtype='<U14')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets load the label encoder which was used during training\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.load('class.npy')\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "y = np.load('label.npy')\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek',\n",
       "       'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek',\n",
       "       'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek',\n",
       "       'ben_afflek', 'ben_afflek', 'elton_john', 'elton_john',\n",
       "       'elton_john', 'elton_john', 'elton_john', 'elton_john',\n",
       "       'elton_john', 'elton_john', 'elton_john', 'elton_john',\n",
       "       'elton_john', 'elton_john', 'elton_john', 'elton_john',\n",
       "       'elton_john', 'elton_john', 'jerry_seinfeld', 'jerry_seinfeld',\n",
       "       'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld',\n",
       "       'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld',\n",
       "       'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld',\n",
       "       'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld',\n",
       "       'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld',\n",
       "       'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'madonna',\n",
       "       'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna',\n",
       "       'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna',\n",
       "       'madonna', 'madonna', 'madonna', 'madonna', 'madonna',\n",
       "       'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling',\n",
       "       'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling',\n",
       "       'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling',\n",
       "       'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling',\n",
       "       'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling',\n",
       "       'mindy_kaling'], dtype='<U14')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1af966497b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define the function to get embeddings for single image\n",
    "def get_embedding_from_image(img):\n",
    "    embedings = list()\n",
    "    img = img_to_array(img)\n",
    "    img1 = img.astype('float32')/255\n",
    "    embedings.append(img1)\n",
    "    a = np.asarray(embedings,dtype=np.float32)\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import cv2, pafy\n",
    "from datetime import datetime\n",
    "url = 'https://www.youtube.com/watch?v=m7zrrj-nD8s'\n",
    "videoPafy = pafy.new(url)\n",
    "best = videoPafy.getbest()\n",
    "# Capture time duration of faces detected\n",
    "faceFound = []\n",
    "ts = [0,0,False,'Unknown']\n",
    "vs = cv2.VideoCapture(0)\n",
    "#vs = cv2.VideoCapture(best.url)\n",
    "#vs = wbcamStream().start()\n",
    "#dict_1 = {\"Naved\":[],\"Zeeshan\":[]}\n",
    "count = 0\n",
    "#face_label=list()\n",
    "#final_db = list()\n",
    "face_recognized = False\n",
    "t_15_min = True\n",
    "\n",
    "while True:\n",
    "    check,frame = vs.read()\n",
    "    count = count+1\n",
    "    \n",
    "    result = detector.detect_faces(frame)\n",
    "    # in the result we will have multiple number of dictionaries for each image, and we need to extract the bounding box of the face.      \n",
    "    if len(result):\n",
    "        if ts[2] == False:\n",
    "            ts[0] = datetime.now()\n",
    "            ts[2] = True\n",
    "        for i in range(len(result)):\n",
    "            (startX,startY,endX,endY)=(result[i][\"box\"][0], result[i][\"box\"][1],result[i][\"box\"][0]+result[i][\"box\"][2], result[i][\"box\"][1] + result[i][\"box\"][3])\n",
    "            confidence = result[i][\"confidence\"]\n",
    "            if (confidence > 0.5):\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                if (startY >=0) and (endY >=0) and (startX >=0) and (endX >=0):\n",
    "                    frame_face = frame[startY:endY, startX:endX]\n",
    "                    frame_face=cv2.resize(frame_face,(128,128))\n",
    "                    embedings=get_embedding_from_image(frame_face)\n",
    "                    prob=classifier_model.predict_proba(embedings)[0].max()\n",
    "                    if prob>=0.80:\n",
    "                        label_name=le.inverse_transform(classifier_model.predict_classes(embedings))[0]\n",
    "                        face_recognized=True\n",
    "                        face_label.append(label_name)\n",
    "                        cv2.putText(frame,label_name,(startX,startY),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "                        ts[3] = label_name\n",
    "                        found=1\n",
    "                        break\n",
    "    else:\n",
    "        if ts[2] == True:\n",
    "            ts[1] = datetime.now()\n",
    "            ts[2] = False\n",
    "            diff = ts[1]-ts[0]\n",
    "            if diff.seconds!=0:\n",
    "                faceFound.append((ts[3], diff.seconds+1, ts[0].strftime(\"%m/%d/%Y %H:%M:%S\"), ts[1].strftime(\"%m/%d/%Y %H:%M:%S\")))\n",
    "                #for label in faceFound:\n",
    "                    #dict_1[label].append((ts[3], diff.seconds+1, ts[0].strftime(\"%m/%d/%Y %H:%M:%S\"), ts[1].strftime(\"%m/%d/%Y %H:%M:%S\")))\n",
    "                    \n",
    "    cv2.imshow(\"web_frame\",frame)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "        \n",
    "vs.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elton_john', 13, '02/15/2020 08:07:05', '02/15/2020 08:07:18'),\n",
       " ('elton_john', 8, '02/15/2020 08:07:29', '02/15/2020 08:07:36'),\n",
       " ('elton_john', 3, '02/15/2020 08:07:41', '02/15/2020 08:07:44'),\n",
       " ('elton_john', 3, '02/15/2020 08:07:46', '02/15/2020 08:07:49'),\n",
       " ('elton_john', 2, '02/15/2020 08:07:51', '02/15/2020 08:07:52'),\n",
       " ('elton_john', 2, '02/15/2020 08:07:57', '02/15/2020 08:07:58'),\n",
       " ('elton_john', 8, '02/15/2020 08:08:03', '02/15/2020 08:08:10'),\n",
       " ('elton_john', 15, '02/15/2020 08:08:12', '02/15/2020 08:08:27'),\n",
       " ('madonna', 9, '02/15/2020 08:08:31', '02/15/2020 08:08:40')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "time_log=pd.DataFrame(faceFound,columns = ('Person Name','total time(sec)','entry time','exit time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person Name</th>\n",
       "      <th>total time(sec)</th>\n",
       "      <th>entry time</th>\n",
       "      <th>exit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>13</td>\n",
       "      <td>02/15/2020 08:07:05</td>\n",
       "      <td>02/15/2020 08:07:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>8</td>\n",
       "      <td>02/15/2020 08:07:29</td>\n",
       "      <td>02/15/2020 08:07:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>3</td>\n",
       "      <td>02/15/2020 08:07:41</td>\n",
       "      <td>02/15/2020 08:07:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>3</td>\n",
       "      <td>02/15/2020 08:07:46</td>\n",
       "      <td>02/15/2020 08:07:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>2</td>\n",
       "      <td>02/15/2020 08:07:51</td>\n",
       "      <td>02/15/2020 08:07:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>2</td>\n",
       "      <td>02/15/2020 08:07:57</td>\n",
       "      <td>02/15/2020 08:07:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>8</td>\n",
       "      <td>02/15/2020 08:08:03</td>\n",
       "      <td>02/15/2020 08:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>elton_john</td>\n",
       "      <td>15</td>\n",
       "      <td>02/15/2020 08:08:12</td>\n",
       "      <td>02/15/2020 08:08:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>madonna</td>\n",
       "      <td>9</td>\n",
       "      <td>02/15/2020 08:08:31</td>\n",
       "      <td>02/15/2020 08:08:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person Name  total time(sec)           entry time            exit time\n",
       "0  elton_john               13  02/15/2020 08:07:05  02/15/2020 08:07:18\n",
       "1  elton_john                8  02/15/2020 08:07:29  02/15/2020 08:07:36\n",
       "2  elton_john                3  02/15/2020 08:07:41  02/15/2020 08:07:44\n",
       "3  elton_john                3  02/15/2020 08:07:46  02/15/2020 08:07:49\n",
       "4  elton_john                2  02/15/2020 08:07:51  02/15/2020 08:07:52\n",
       "5  elton_john                2  02/15/2020 08:07:57  02/15/2020 08:07:58\n",
       "6  elton_john                8  02/15/2020 08:08:03  02/15/2020 08:08:10\n",
       "7  elton_john               15  02/15/2020 08:08:12  02/15/2020 08:08:27\n",
       "8     madonna                9  02/15/2020 08:08:31  02/15/2020 08:08:40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(time_log,'time_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import cv2, pafy\n",
    "\n",
    "vs = cv2.VideoCapture(0)\n",
    "#vs = wbcamStream().start()\n",
    "#dict_1 = {\"Naved\":[],\"Zeeshan\":[]}\n",
    "count = 0\n",
    "face_label=list()\n",
    "final_db = list()\n",
    "\n",
    "\n",
    "while True:\n",
    "    check,frame = vs.read()\n",
    "    count = count+1\n",
    "    result = detector.detect_faces(frame)\n",
    "    for i in range(len(result)):\n",
    "        (startX,startY,endX,endY)=(result[i][\"box\"][0], result[i][\"box\"][1],result[i][\"box\"][0]+result[i][\"box\"][2], result[i][\"box\"][1] + result[i][\"box\"][3])\n",
    "        confidence = result[i][\"confidence\"]\n",
    "        if (confidence > 0.5):\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            if (startY >=0) and (endY >=0) and (startX >=0) and (endX >=0):\n",
    "                frame_face = frame[startY:endY, startX:endX]\n",
    "                frame_face=cv2.resize(frame_face,(128,128))\n",
    "                embedings=get_embedding_from_image(frame_face)\n",
    "                prob=classifier_model.predict_proba(embedings)[0].max()\n",
    "                #prob=classifier_model.predict_proba(embedings)[0].max()\n",
    "                if prob>=0.80:\n",
    "                    label_name=le.inverse_transform(classifier_model.predict_classes(embedings))[0]\n",
    "                    #face_recognized=True\n",
    "                    #face_label.append(label_name)\n",
    "                    cv2.putText(frame,label_name,(startX,startY),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "\n",
    "                    #try:\n",
    "                     #   cv2.imwrite(time_wise_face_path+\"\\\\\"+label_name+'\\\\'+str(time_detected).replace(\" \",\"_\").replace(\":\",\"_\")+'.jpg',frame_face)\n",
    "                    #except:\n",
    "                     #   pass\n",
    "                else:\n",
    "                    face_recognized=False\n",
    "    cv2.imshow(\"web_frame\",frame)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "        \n",
    "vs.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
